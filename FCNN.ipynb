{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NtaDdR7I_CVf",
        "cWJJS-Ie1G0u",
        "9KLB2LHlcx1h"
      ],
      "authorship_tag": "ABX9TyOWot9+vTfmgro8VW5XiMqg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/19G12/DL_scratch/blob/main/FCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Day 1**\n",
        "\n",
        "*   Load and normalize MNIST Data\n",
        "*   Linear with He initialization (weights from gaussian dist)\n",
        "*   Implement ReLU\n",
        "*   Chain 2 levels with RELU and do a forward pass"
      ],
      "metadata": {
        "id": "NtaDdR7I_CVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import gzip\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "xN__J2v0BSYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We already have train and test split data\n",
        "\n",
        "mnist_test = pd.read_csv('/content/sample_data/mnist_test.csv')\n",
        "mnist_train = pd.read_csv('/content/sample_data/mnist_train_small.csv')\n",
        "\n",
        "Y_train = mnist_train.iloc[:, 0].to_numpy()\n",
        "X_train = mnist_train.iloc[:, 1:].to_numpy().reshape(-1, 28*28)/255\n",
        "\n",
        "Y_test = mnist_test.iloc[:, 0].to_numpy()\n",
        "X_test = mnist_test.iloc[:, 1:].to_numpy().reshape(-1, 28*28)/255"
      ],
      "metadata": {
        "id": "Ixw3RRs8DZ7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train shape:\", X_train.shape, Y_train.shape)\n",
        "print(\"Test shape:\", X_test.shape, Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2OI7SfTEMis",
        "outputId": "5ee3abf4-9e16-4504-e6cd-f30a1e3c3801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (19999, 784) (19999,)\n",
            "Test shape: (9999, 784) (9999,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Linear Layer with He initialization\n",
        "\n",
        "class LinearLayer:\n",
        "\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    self.W = np.random.randn(input_dim, output_dim) * np.sqrt(2. /input_dim)\n",
        "    self.b = np.zeros((1, output_dim))\n",
        "    self.dW = 0\n",
        "    self.db = 0\n",
        "\n",
        "  def forward(self, X):\n",
        "    self.X = X\n",
        "    return np.dot(X, self.W) + self.b # Numpy broadcasting\n",
        "\n",
        "  # Day2\n",
        "  def backward(self, dL_dY):\n",
        "    self.dW = np.dot(self.X.T, dL_dY)\n",
        "    self.db = np.sum(dL_dY, axis=0, keepdims=True)\n",
        "    return np.dot(dL_dY, self.W.T) # This is h(k-1) layer"
      ],
      "metadata": {
        "id": "vuv0he53HGE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## RelU activation\n",
        "\n",
        "class ReLU:\n",
        "\n",
        "  def forward(self,X):\n",
        "    self.mask = X>0\n",
        "    return X*self.mask\n",
        "\n",
        "  # Day2\n",
        "  def backward(self, grad_output):\n",
        "    return self.mask * grad_output"
      ],
      "metadata": {
        "id": "NCqXx_KgILPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## LeakyRelu activation\n",
        "\n",
        "class LeakyRelU:\n",
        "\n",
        "  def forward(self, X):\n",
        "    self.mask = X>0\n",
        "    return X*np.where(self.mask, 1, 0.01)\n",
        "\n",
        "  # Day2\n",
        "  def backward(self, grad_output):\n",
        "    return grad_output * np.where(self.mask, 1, 0.01)"
      ],
      "metadata": {
        "id": "yUrfzDnBwDaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Compute safe softmax and cross entropy loss, from logits input - Day2\n",
        "\n",
        "def softmax_cross_entropy_loss(logits, labels):\n",
        "\n",
        "  exp = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
        "  softmax = exp / np.sum(exp, axis=1, keepdims=True)\n",
        "\n",
        "  batch_size = logits.shape[0]\n",
        "  correct_logprobs = -np.log(softmax[np.arange(batch_size), labels] + 1e-9)\n",
        "  loss = np.sum(correct_logprobs) / batch_size\n",
        "  return softmax, loss"
      ],
      "metadata": {
        "id": "XWv-43g8lV9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Gradients of loss at output layer - Day2\n",
        "\n",
        "def softmax_cross_entropy_loss_backward(softmax_probs, labels):\n",
        "\n",
        "  batch_size = softmax_probs.shape[0]\n",
        "  grad = softmax_probs.copy()\n",
        "  grad[np.arange(batch_size), labels] -= 1\n",
        "  grad /= batch_size\n",
        "  return grad"
      ],
      "metadata": {
        "id": "zRaWaz2Koiti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Make a dummy network 3 layer deep\n",
        "\n",
        "layer1 = LinearLayer(784,128)\n",
        "relu1 = ReLU()\n",
        "layer2 = LinearLayer(128, 64)\n",
        "relu2 = ReLU()\n",
        "layer3 = LinearLayer(64, 10)\n",
        "\n",
        "def forward_pass(x):\n",
        "  layer1_out = layer1.forward(x)\n",
        "  relu1_out = relu1.forward(layer1_out)\n",
        "  layer2_out = layer2.forward(relu1_out)\n",
        "  relu2_out = relu2.forward(layer2_out)\n",
        "  layer3_out = layer3.forward(relu2_out)\n",
        "  return layer3_out\n"
      ],
      "metadata": {
        "id": "TvpdK2kaJLra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Make a minibatch and pass\n",
        "\n",
        "X_batch = X_train[:5]\n",
        "Y_batch = Y_train[:5]\n",
        "\n",
        "out = forward_pass(X_batch)\n",
        "print(\"Output shape: \", out.shape)\n",
        "print(\"Output logits: \", out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNIKzu8hKq_R",
        "outputId": "0a374f63-b122-498d-e841-af5b6c06eb8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape:  (5, 10)\n",
            "Output logits:  [[ 0.27687057 -0.6981354  -0.66782025 -0.14167052  0.62019475  0.32296846\n",
            "  -0.70735487 -0.43305741 -0.39987477 -0.3719002 ]\n",
            " [-0.29078071 -0.7938101  -0.63673306  0.03034183 -0.33481601  0.73639029\n",
            "  -0.11591442 -0.53626534 -0.97250719  0.60936038]\n",
            " [ 0.04149395 -0.38661013 -0.6404815  -0.10705742 -0.49497382  0.33926206\n",
            "  -0.74186933 -0.45792528 -0.75038952  0.13025264]\n",
            " [ 0.18981326 -0.30410043 -0.31195133 -0.17597901  0.00403582  0.00217031\n",
            "  -0.3087758  -0.14603987 -0.31820903 -0.2874532 ]\n",
            " [-0.14529557 -0.25184454 -0.77338255  0.12671598 -0.23811856 -0.62026095\n",
            "  -0.42113235 -0.48517241 -0.60102408  0.20466321]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Day 2**\n",
        "\n",
        "1.   Implement forward pass\n",
        "2.   Implement cross_entropy loss\n",
        "3.   Implement backpropagation\n",
        "4.   Prepare for weight updates"
      ],
      "metadata": {
        "id": "zSgkRJ71jFFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Forward propagation\n",
        "## The above changes has been made to the earlier code itself\n",
        "\n",
        "X_batch = X_train[:5]\n",
        "Y_batch = Y_train[:5]\n",
        "\n",
        "out = forward_pass(X_batch)\n",
        "probs, loss1 = softmax_cross_entropy_loss(out, Y_batch)"
      ],
      "metadata": {
        "id": "sV_KlGFTj9F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Back-tracking\n",
        "softmax_grad = softmax_cross_entropy_loss_backward(probs, Y_batch)\n",
        "grad = layer3.backward(softmax_grad)\n",
        "grad = relu2.backward(grad)\n",
        "grad = layer2.backward(grad)\n",
        "grad = relu1.backward(grad)\n",
        "fin_grad = layer1.backward(grad)\n",
        "\n",
        "# Update all layer weights with simple GD\n",
        "learning_rate = 0.01\n",
        "layer1.W -= learning_rate * layer1.dW\n",
        "layer1.b -= learning_rate * layer1.db\n",
        "\n",
        "layer2.W -= learning_rate * layer2.dW\n",
        "layer2.b -= learning_rate * layer2.db\n",
        "\n",
        "layer3.W -= learning_rate * layer3.dW\n",
        "layer3.b -= learning_rate * layer3.db"
      ],
      "metadata": {
        "id": "cirQyyLsGwBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = forward_pass(X_batch)\n",
        "probs, loss2 = softmax_cross_entropy_loss(out, Y_batch)"
      ],
      "metadata": {
        "id": "qH2srfwGH58W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0a9204a-2470-40de-d83b-d133d0445ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30-801773364.py:9: RuntimeWarning: divide by zero encountered in log\n",
            "  correct_logprobs = -np.log(softmax[np.arange(batch_size), labels])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Loss before update: {loss1}\")\n",
        "print(f\"Loss after update: {loss2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4AkxWzRH8yP",
        "outputId": "b8b6fef6-2380-45d4-d374-f87fe7b67a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss before update: 2.303174376519629\n",
            "Loss after update: inf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Day 3**\n",
        "\n",
        "\n",
        "1.   Implement Adam optimizer\n",
        "2.   Add Dropout\n",
        "3.   Implement one train epoch\n",
        "4.   Evaluate accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "cWJJS-Ie1G0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD_momentum:\n",
        "\n",
        "  def __init__(self, params, learning_rate=0.01):\n",
        "    self.params = params\n",
        "    self.lr = learning_rate\n",
        "    self.momentum = [np.zeros_like(p) for p,_ in params]\n",
        "\n",
        "  def iterate(self):\n",
        "\n",
        "    for i, (p, grad) in enumerate(self.params):\n",
        "\n",
        "      self.momentum[i] = 0.9 * self.momentum[i] + (1 - 0.9) * grad\n",
        "      p[...] -= self.lr * self.momentum[i]"
      ],
      "metadata": {
        "id": "wvey4uH2oimD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dropout:\n",
        "\n",
        "  def __init__(self, p, training=True):\n",
        "    self.p = p\n",
        "    self.mask = None\n",
        "    self.training = training\n",
        "\n",
        "  def forward(self, x):\n",
        "    if not self.training:\n",
        "      return x\n",
        "    self.mask = (np.random.randn(*x.shape) > self.p)/(1 - self.p)\n",
        "    return x*self.mask\n",
        "\n",
        "  def backward(self, grad):\n",
        "    return grad*self.mask"
      ],
      "metadata": {
        "id": "l0D9gG0MygPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropout1 = Dropout(0.0)\n",
        "dropout2 = Dropout(0.0)\n",
        "\n",
        "def forward_with_dropout(x):\n",
        "\n",
        "  layer1_out = layer1.forward(x)\n",
        "  relu1_out = relu1.forward(layer1_out)\n",
        "  dropout1_out = dropout1.forward(relu1_out)\n",
        "\n",
        "  layer2_out = layer2.forward(dropout1_out)\n",
        "  relu2_out = relu2.forward(layer2_out)\n",
        "  dropout2_out = dropout2.forward(relu2_out)\n",
        "\n",
        "  layer3_out = layer3.forward(dropout2_out)\n",
        "  return layer3_out"
      ],
      "metadata": {
        "id": "xAU7iQt36ohw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Initalize adam optimizer\n",
        "\n",
        "sgdm = SGD_momentum(params = [(layer1.W, layer1.dW), (layer1.b, layer1.db),\n",
        "                               (layer2.W, layer2.dW), (layer2.b, layer2.db),\n",
        "                               (layer3.W, layer3.dW), (layer3.b, layer3.db)])"
      ],
      "metadata": {
        "id": "fTLW4qrw8BCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Epoch wise training loop\n",
        "\n",
        "num_epochs = 15\n",
        "batch_size = 32\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  total_loss = 0\n",
        "  total_samples = 0\n",
        "\n",
        "  for i in range(0, len(X_train), batch_size):\n",
        "    X_batch = X_train[i:i+batch_size]\n",
        "    Y_batch = Y_train[i:i+batch_size]\n",
        "\n",
        "    # Forward pass\n",
        "    out = forward_with_dropout(X_batch)\n",
        "    probs, loss = softmax_cross_entropy_loss(out, Y_batch)\n",
        "\n",
        "    # Sanity check\n",
        "    print(\"Logits:\", out[0])\n",
        "    print(\"Softmax:\", probs[0])\n",
        "    print(\"Predicted Label:\", np.argmax(probs[0]))\n",
        "    print(\"True Label:\", Y_batch[0])\n",
        "\n",
        "    total_loss += loss * X_batch.shape[0]   # un-average the loss\n",
        "    total_samples += X_batch.shape[0]\n",
        "\n",
        "    # Backward pass\n",
        "    softmax_grad = softmax_cross_entropy_loss_backward(probs, Y_batch)\n",
        "    grad = layer3.backward(softmax_grad)\n",
        "    grad = dropout2.backward(grad, True)\n",
        "    grad = relu2.backward(grad)\n",
        "    grad = layer2.backward(grad)\n",
        "    grad = dropout1.backward(grad, True)\n",
        "    grad = relu1.backward(grad)\n",
        "    grad = layer1.backward(grad)\n",
        "\n",
        "    sgdm.iterate()\n",
        "\n",
        "    print(layer1.W.__array_interface__['data'][0])\n",
        "    print(sgdm.params[0][0].__array_interface__['data'][0])\n",
        "\n",
        "  avg_loss = total_loss / total_samples\n"
      ],
      "metadata": {
        "id": "ox3AIlilFXFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Day 4**\n",
        "\n",
        "1.   Create validation instance\n",
        "2.   Forward without dropout\n"
      ],
      "metadata": {
        "id": "9KLB2LHlcx1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Implement forward without dropout\n",
        "\n",
        "def forward_without_dropout(x):\n",
        "  layer1_out = layer1.forward(x)\n",
        "  relu1_out = relu1.forward(layer1_out)\n",
        "  layer2_out = layer2.forward(relu1_out)\n",
        "  relu2_out = relu2.forward(layer2_out)\n",
        "  layer3_out = layer3.forward(relu2_out)\n",
        "  return layer3_out"
      ],
      "metadata": {
        "id": "gHZjoWXddCxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Evaluate validation loss\n",
        "\n",
        "def evaluate_validation_loss(X_val, Y_val, batch_size = 32):\n",
        "\n",
        "  total_loss = 0\n",
        "  total_samples = 0\n",
        "\n",
        "  for i in range(0,len(X_val),batch_size):\n",
        "\n",
        "    X_batch = X_val[i:i+batch_size]\n",
        "    Y_batch = Y_val[i:i+batch_size]\n",
        "\n",
        "    out = forward_without_dropout(X_batch)\n",
        "    probs, loss = softmax_cross_entropy_loss(out, Y_batch)\n",
        "\n",
        "    total_loss += loss * X_batch.shape[0]\n",
        "    total_samples += X_batch.shape[0]\n",
        "\n",
        "  avg_loss = total_loss / total_samples\n",
        "  return avg_loss"
      ],
      "metadata": {
        "id": "tCmb4GZhdoTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Split training into traiing and validation\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, random_state=42, test_size=0.1)"
      ],
      "metadata": {
        "id": "oEfubZLQeysI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Epoch wise training and validation loop\n",
        "\n",
        "num_epochs = 50\n",
        "batch_size = 32\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  total_loss = 0\n",
        "  total_samples = 0\n",
        "\n",
        "  for i in range(0, len(X_train), batch_size):\n",
        "    X_batch = X_train[i:i+batch_size]\n",
        "    Y_batch = Y_train[i:i+batch_size]\n",
        "\n",
        "    # Forward pass\n",
        "    out = forward_with_dropout(X_batch)\n",
        "    probs, loss = softmax_cross_entropy_loss(out, Y_batch)\n",
        "\n",
        "    total_loss += loss * X_batch.shape[0]   # un-average the loss\n",
        "    total_samples += X_batch.shape[0]\n",
        "\n",
        "    # Backward pass\n",
        "    softmax_grad = softmax_cross_entropy_loss_backward(probs, Y_batch)\n",
        "    grad = layer3.backward(softmax_grad)\n",
        "    grad = dropout2.backward(grad)\n",
        "    grad = relu2.backward(grad)\n",
        "    grad = layer2.backward(grad)\n",
        "    grad = dropout1.backward(grad)\n",
        "    grad = relu1.backward(grad)\n",
        "    grad = layer1.backward(grad)\n",
        "\n",
        "    for param, grad in sgdm.params:\n",
        "      param[...] -= 0.01 * grad\n",
        "\n",
        "  print(\"W[0,0] after:\", np.mean(layer1.W))\n",
        "  print(layer1.W.__array_interface__['data'][0])\n",
        "  print(sgdm.params[0][0].__array_interface__['data'][0])\n",
        "\n",
        "  val_avg_loss = evaluate_validation_loss(X_val, Y_val) # Validation loss\n",
        "  avg_train_loss = total_loss / total_samples # Train loss\n",
        "  print(f\"Epoch: {epoch}, Train Loss: {avg_train_loss}, Val Loss: {val_avg_loss}\")"
      ],
      "metadata": {
        "id": "QgW-5pgxeloM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overfitting debugging"
      ],
      "metadata": {
        "id": "2AbtOZi0BT6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_batch = X_train[:32]\n",
        "Y_batch = Y_train[:32]\n",
        "\n",
        "num_epochs = 150\n",
        "lr = 0.01\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward\n",
        "    out = forward_without_dropout(X_batch)\n",
        "    probs, loss = softmax_cross_entropy_loss(out, Y_batch)\n",
        "\n",
        "    # Accuracy\n",
        "    acc = np.mean(np.argmax(probs, axis=1) == Y_batch)\n",
        "\n",
        "    # Backward\n",
        "    grad = softmax_cross_entropy_loss_backward(probs, Y_batch)\n",
        "    grad = layer3.backward(grad)\n",
        "    grad = relu2.backward(grad)\n",
        "    grad = layer2.backward(grad)\n",
        "    grad = relu1.backward(grad)\n",
        "    grad = layer1.backward(grad)\n",
        "\n",
        "    # SGD\n",
        "    for param, grad in [(layer1.W, layer1.dW), (layer1.b, layer1.db),\n",
        "                        (layer2.W, layer2.dW), (layer2.b, layer2.db),\n",
        "                        (layer3.W, layer3.dW), (layer3.b, layer3.db)]:\n",
        "        param -= lr * grad\n",
        "\n",
        "    print(f\"Epoch {epoch+1:3d}: Loss = {loss:.4f}, Accuracy = {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "Mj9rlDOKyT7K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "d4167a2a-6c4d-4fac-94f7-812ede4b06f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-1465357348.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mY_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Complete Model implementation**"
      ],
      "metadata": {
        "id": "FCEmMsGUEpvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearLayer:\n",
        "\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    self.W = np.random.randn(input_dim, output_dim) * np.sqrt(2. /input_dim)\n",
        "    self.b = np.zeros((1, output_dim))\n",
        "    self.dW = 0\n",
        "    self.db = 0\n",
        "\n",
        "  def forward(self, X):\n",
        "    self.X = X\n",
        "    return np.dot(X, self.W) + self.b # Numpy broadcasting\n",
        "\n",
        "  # Day2\n",
        "  def backward(self, dL_dY):\n",
        "    self.dW = np.dot(self.X.T, dL_dY)\n",
        "    self.db = np.sum(dL_dY, axis=0, keepdims=True)\n",
        "    return np.dot(dL_dY, self.W.T) # This is h(k-1) layer"
      ],
      "metadata": {
        "id": "PC9tC_uPE0qW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ReLU:\n",
        "\n",
        "  def forward(self,X):\n",
        "    self.mask = X>0\n",
        "    return X*self.mask\n",
        "\n",
        "  # Day2\n",
        "  def backward(self, grad_output):\n",
        "    return self.mask * grad_output"
      ],
      "metadata": {
        "id": "rpbRZAoaFA9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_cross_entropy_loss(logits, labels):\n",
        "\n",
        "  exp = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
        "  softmax = exp / np.sum(exp, axis=1, keepdims=True)\n",
        "\n",
        "  batch_size = logits.shape[0]\n",
        "  correct_logprobs = -np.log(softmax[np.arange(batch_size), labels] + 1e-9)\n",
        "  loss = np.sum(correct_logprobs) / batch_size\n",
        "  return softmax, loss"
      ],
      "metadata": {
        "id": "wOw8uUa-FIsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Gradients of loss at output layer - Day2\n",
        "\n",
        "def softmax_cross_entropy_loss_backward(softmax_probs, labels):\n",
        "\n",
        "  batch_size = softmax_probs.shape[0]\n",
        "  grad = softmax_probs.copy()\n",
        "  grad[np.arange(batch_size), labels] -= 1\n",
        "  grad /= batch_size\n",
        "  return grad"
      ],
      "metadata": {
        "id": "xbiLUrjzFTHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Execute this before any training to reset weights\n",
        "\n",
        "layer1 = LinearLayer(784,128)\n",
        "relu1 = ReLU()\n",
        "layer2 = LinearLayer(128, 64)\n",
        "relu2 = ReLU()\n",
        "layer3 = LinearLayer(64, 10)"
      ],
      "metadata": {
        "id": "XLinCCzIFaPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch normalization is not very helpful for such small batch size and shallow network\n",
        "\n",
        "class Param:\n",
        "    def __init__(self, param, grad_fn):\n",
        "        self.param = param\n",
        "        self.grad_fn = grad_fn\n",
        "\n",
        "    @property\n",
        "    def grad(self):\n",
        "        return self.grad_fn()\n",
        "\n",
        "\n",
        "class Adam:\n",
        "    def __init__(self, params, lr=0.00025, beta1=0.9, beta2=0.999, eps=1e-8):\n",
        "        self.params = params\n",
        "        self.lr = lr\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.eps = eps\n",
        "\n",
        "        self.m = [np.zeros_like(param.param) for param in params]  # First moment\n",
        "        self.v = [np.zeros_like(param.param) for param in params]  # Second moment\n",
        "        self.t = 0  # Time step\n",
        "\n",
        "    def iterate(self):\n",
        "        self.t += 1\n",
        "        for i, param in enumerate(self.params):\n",
        "            grad = param.grad  # grad is now a property\n",
        "\n",
        "            self.m[i] = self.beta1 * self.m[i] + (1 - self.beta1) * grad\n",
        "            self.v[i] = self.beta2 * self.v[i] + (1 - self.beta2) * (grad ** 2)\n",
        "\n",
        "            m_hat = self.m[i] / (1 - self.beta1 ** self.t)\n",
        "            v_hat = self.v[i] / (1 - self.beta2 ** self.t)\n",
        "\n",
        "            param.param -= self.lr * m_hat / (np.sqrt(v_hat) + self.eps)\n",
        "\n",
        "\n",
        "\n",
        "class Dropout:\n",
        "\n",
        "  def __init__(self, p, training=True):\n",
        "    self.p = p\n",
        "    self.mask = None\n",
        "    self.training = training\n",
        "\n",
        "  def forward(self, x):\n",
        "    if not self.training:\n",
        "      return x\n",
        "    self.mask = (np.random.randn(*x.shape) > self.p)/(1 - self.p)\n",
        "    return x*self.mask\n",
        "\n",
        "  def backward(self, grad):\n",
        "    return grad*self.mask\n",
        "\n",
        "\n",
        "dropout1 = Dropout(0.3)\n",
        "dropout2 = Dropout(0.2)\n",
        "\n",
        "\n",
        "adam = Adam([\n",
        "    Param(layer1.W, lambda: layer1.dW),\n",
        "    Param(layer1.b, lambda: layer1.db),\n",
        "    Param(layer2.W, lambda: layer2.dW),\n",
        "    Param(layer2.b, lambda: layer2.db),\n",
        "    Param(layer3.W, lambda: layer3.dW),\n",
        "    Param(layer3.b, lambda: layer3.db),\n",
        "])"
      ],
      "metadata": {
        "id": "_EwZ_AYEFi_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def forward_with_dropout(x):\n",
        "\n",
        "  layer1_out = layer1.forward(x)\n",
        "  relu1_out = relu1.forward(layer1_out)\n",
        "  dropout1_out = dropout1.forward(relu1_out)\n",
        "\n",
        "  layer2_out = layer2.forward(dropout1_out)\n",
        "  relu2_out = relu2.forward(layer2_out)\n",
        "  dropout2_out = dropout2.forward(relu2_out)\n",
        "\n",
        "  layer3_out = layer3.forward(dropout2_out) #Classification layer\n",
        "  return layer3_out\n",
        "\n",
        "def forward_without_dropout(x):\n",
        "  layer1_out = layer1.forward(x)\n",
        "  relu1_out = relu1.forward(layer1_out)\n",
        "  layer2_out = layer2.forward(relu1_out)\n",
        "  relu2_out = relu2.forward(layer2_out)\n",
        "  layer3_out = layer3.forward(relu2_out)\n",
        "  return layer3_out"
      ],
      "metadata": {
        "id": "dU_dwxiJGDtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_validation_loss(X_val, Y_val, batch_size = 32):\n",
        "\n",
        "  total_loss = 0\n",
        "  total_samples = 0\n",
        "\n",
        "  for i in range(0,len(X_val),batch_size):\n",
        "\n",
        "    X_batch = X_val[i:i+batch_size]\n",
        "    Y_batch = Y_val[i:i+batch_size]\n",
        "\n",
        "    out = forward_without_dropout(X_batch)\n",
        "    probs, loss = softmax_cross_entropy_loss(out, Y_batch)\n",
        "\n",
        "    total_loss += loss * X_batch.shape[0]\n",
        "    total_samples += X_batch.shape[0]\n",
        "\n",
        "  avg_loss = total_loss / total_samples\n",
        "  return avg_loss"
      ],
      "metadata": {
        "id": "Vss6ZNH_GQEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, random_state=42, test_size=0.1)"
      ],
      "metadata": {
        "id": "l5BWFgafGUSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_epochs = 15\n",
        "batch_size = 32\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    total_loss = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "\n",
        "        X_batch = X_train[i:i+batch_size]\n",
        "        Y_batch = Y_train[i:i+batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        out = forward_with_dropout(X_batch)\n",
        "        probs, loss = softmax_cross_entropy_loss(out, Y_batch)\n",
        "\n",
        "        total_loss += loss * X_batch.shape[0]   # un-average the loss\n",
        "        total_samples += X_batch.shape[0]\n",
        "\n",
        "        # Backward pass\n",
        "        softmax_grad = softmax_cross_entropy_loss_backward(probs, Y_batch)\n",
        "        grad = layer3.backward(softmax_grad)\n",
        "        grad = dropout2.backward(grad)\n",
        "        grad = relu2.backward(grad)\n",
        "        grad = layer2.backward(grad)\n",
        "        grad = dropout1.backward(grad)\n",
        "        grad = relu1.backward(grad)\n",
        "        grad = layer1.backward(grad)\n",
        "\n",
        "        adam.iterate()\n",
        "\n",
        "    # Average train and val loss\n",
        "    avg_train_loss = total_loss / total_samples\n",
        "    val_avg_loss = evaluate_validation_loss(X_val, Y_val)\n",
        "\n",
        "    # Save losses for plotting\n",
        "    train_losses.append(avg_train_loss)\n",
        "    val_losses.append(val_avg_loss)\n",
        "\n",
        "    print(f\"Epoch: {epoch}, Train Loss: {avg_train_loss}, Val Loss: {val_avg_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Lv_VkRcGfHQ",
        "outputId": "62650a9f-7d19-4bc7-f12b-72fde71251c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Train Loss: 1.8357757156003103, Val Loss: 0.6830366327128851\n",
            "Epoch: 1, Train Loss: 1.1344301123690588, Val Loss: 0.5562001292940026\n",
            "Epoch: 2, Train Loss: 0.8819383230502417, Val Loss: 0.4999574905693926\n",
            "Epoch: 3, Train Loss: 0.7557586396257077, Val Loss: 0.49070822408658055\n",
            "Epoch: 4, Train Loss: 0.6797118843142673, Val Loss: 0.47927139799208013\n",
            "Epoch: 5, Train Loss: 0.6063064624565838, Val Loss: 0.4484063150393465\n",
            "Epoch: 6, Train Loss: 0.5799274932897134, Val Loss: 0.439867624331919\n",
            "Epoch: 7, Train Loss: 0.53257376297005, Val Loss: 0.44742694327586124\n",
            "Epoch: 8, Train Loss: 0.5086844750268276, Val Loss: 0.4174723047274887\n",
            "Epoch: 9, Train Loss: 0.4812530129181618, Val Loss: 0.4123473290823987\n",
            "Epoch: 10, Train Loss: 0.4649187848360124, Val Loss: 0.41006104904363466\n",
            "Epoch: 11, Train Loss: 0.4425302267725911, Val Loss: 0.3935017041494045\n",
            "Epoch: 12, Train Loss: 0.4195911105694928, Val Loss: 0.40732586326483106\n",
            "Epoch: 13, Train Loss: 0.4085974004613115, Val Loss: 0.3810552965472839\n",
            "Epoch: 14, Train Loss: 0.40054887209800716, Val Loss: 0.3709615892415508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "kwchdT4yRzDr",
        "outputId": "54177441-4ede-4626-df37-5fbafb79ace7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Test the accuracy, precision and recall for the trained model\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "\n",
        "def evaluate_model(model, X_test, Y_test):\n",
        "\n",
        "    logits = model.forward(X_test, training=False)\n",
        "\n",
        "    y_pred = np.argmax(logits, axis=1)\n",
        "\n",
        "    y_true = Y_test\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    report = classification_report(y_true, y_pred, digits=4)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    return accuracy, precision, recall, report, cm\n",
        "\n"
      ],
      "metadata": {
        "id": "YdegaFhRwm3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel:\n",
        "    def __init__(self):\n",
        "        self.layer1 = layer1\n",
        "        self.dropout1 = dropout1\n",
        "        self.relu1 = relu1\n",
        "        self.layer2 = layer2\n",
        "        self.dropout2 = dropout2\n",
        "        self.relu2 = relu2\n",
        "        self.layer3 = layer3\n",
        "\n",
        "    def forward(self, x, training=True):\n",
        "        out = self.layer1.forward(x)\n",
        "        out = self.relu1.forward(out)\n",
        "        if training:\n",
        "            out = self.dropout1.forward(out)\n",
        "\n",
        "        out = self.layer2.forward(out)\n",
        "        out = self.relu2.forward(out)\n",
        "        if training:\n",
        "            out = self.dropout2.forward(out)\n",
        "\n",
        "        out = self.layer3.forward(out)\n",
        "\n",
        "        # Softmax for classification\n",
        "        exp = np.exp(out - np.max(out, axis=1, keepdims=True))\n",
        "        softmax_out = exp / np.sum(exp, axis=1, keepdims=True)\n",
        "\n",
        "        return softmax_out\n"
      ],
      "metadata": {
        "id": "ynrwEWkwCJ4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel()\n",
        "\n",
        "accuracy, precision, recall, report, cm = evaluate_model(model, X_test, Y_test)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(\"Classification Report:\\n\", report)\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvnQerE7Fa-j",
        "outputId": "1f234702-f08a-4482-df2d-2d8de6e51c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9345\n",
            "Precision: 0.9344\n",
            "Recall: 0.9345\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9387    0.9847    0.9612       980\n",
            "           1     0.9695    0.9806    0.9750      1135\n",
            "           2     0.9407    0.9225    0.9315      1032\n",
            "           3     0.9172    0.9327    0.9249      1010\n",
            "           4     0.9138    0.9389    0.9262       982\n",
            "           5     0.9326    0.8845    0.9079       892\n",
            "           6     0.9378    0.9593    0.9484       958\n",
            "           7     0.9404    0.9377    0.9391      1027\n",
            "           8     0.9214    0.8901    0.9055       974\n",
            "           9     0.9268    0.9039    0.9152      1009\n",
            "\n",
            "    accuracy                         0.9345      9999\n",
            "   macro avg     0.9339    0.9335    0.9335      9999\n",
            "weighted avg     0.9344    0.9345    0.9343      9999\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 965    0    1    1    0    3    6    2    2    0]\n",
            " [   0 1113    3    4    1    0    3    2    9    0]\n",
            " [   8    6  952   10   10    0    9   12   23    2]\n",
            " [   4    2   19  942    1   17    0   13    9    3]\n",
            " [   1    0    5    0  922    1   15    2    3   33]\n",
            " [  12    1    1   35    6  789   15    6   23    4]\n",
            " [  16    3    1    1    7    8  919    1    2    0]\n",
            " [   3   10   21    3    7    0    1  963    0   19]\n",
            " [   8    8    9   17   12   19   11   12  867   11]\n",
            " [  11    5    0   14   43    9    1   11    3  912]]\n"
          ]
        }
      ]
    }
  ]
}